{% extends "blog/rp/rp_header.html" %}
{% block content %}
{% load staticfiles %}

<style>
	figure img {
		display: block;
		margin: 0 auto;
		width: 50%;
		text-align: center;
	}
	figcaption {
		text-align: center;
	}
</style>

<head>
  <link rel="stylesheet" type="text/css" href="{% static 'usa_website/css/blogheader.css' %}" />
  <script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>

<div class="container-fluid" >
	  <h1>Data Secrets</h1>
	  <h2>
	    <img class = "icon" src="/static/usa_website/images/logos/logo_square.png" style='vertical-align: middle'></img>
	    <span style="color: gray" id="author">PM: </span>
	    <span style="color: gray" id="name">Lucas Bandarkar</span>
	    <img class = "icon" src="/static/usa_website/images/logos/logo_square.png" style='vertical-align: middle'></img>
	    <span style="color: gray" id="author">Consultants: </span>
	    <span style="color: gray" id="date">Haoming Guo, Gwyneth Ang, Zoe Liu, Hans Sit, Oscar Syu, Ewen Dai, Shivansh Kumar</span>
	  </h2>

	  <img class = "titlePic" src="{% static 'usa_website/images/dataconsulting/fa19/cuztheoldoneisshit.jpg' %}" style="margin:auto; margin-bottom:20px;"></img><br><br>

	<h3>Project Description</h3>
    <p>
	   In Fall 2019, SAAS worked on a natural language processing project with Palo Alto data security startup Data Secrets. We were tasked with doing research into a problem who’s specific details we are not fully allowed to discuss. However, we were in essence looking to establish relationships between pieces of textual data across separate repositories that lacked cross-repository identifiers (like a unique key). For this problem, our first main objective was find a dataset that could model the real-life problem. We explored the Enron email dataset on Kaggle and web-scraped a dataset of Reddit threads. The analogy between these datasets and the problem was that if we were able to, after stripping the meta-data, reconstruct the threads based purely on the text content, we’d be able to reconstruct lost relationships across the repositories. For various reasons, the dataset we ended up with was one we created by web-scraping a number of websites with web pages about celebrities.</p>
<p> Our first approach was a classic NLP approach of vectorizing the pieces of data and clustering. After preprocessing each piece of text into arrays of lemmatized, stemmed, non-stop words, we fleshed out multiple techniques to map to a vector space. We concluded that the most optimal for our problem was using Facebook’s pre-trained FastText model (a word2vec model) to vectorize all the words, and then use term frequency-inverse document frequency to aggregate the words into a single 300-dimension vectors. After extensive research on numerous automatic clustering algorithms, we concluded that for our problem density-based clustering would work best. We implemented DBSCAN and HDBSCAN, both with low min-point and low alpha parameters to maintain the cluster sizes low.</p>
<p> Our second approach stemmed from the Gale-Shapley algorithm (Stable Marriage) for bipartite matching. The idea is that if we can calculate a similarity score between two pieces of data, we can iteratively match or not match pieces of data across repositories. Because there was no notion of distance, we don’t need to map text to vector spaces, allowing us to hold more information. We used a TF-IDF weighted Jaccard index on the sets of preprocessed words in two pieces of text to calculate similarity scores. We then iteratively matched, unmatched, and re-matched pieces of data based on shifting criteria. This strategy yielded much higher results than our classic clustering approach, but it’s runtime was much higher.</p>
<h3>Presentation</h3>
<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vSz0NzeOYs4kZISc1JyyPnV2zoLAJlegrcxw_iR51XAS1B-j9W9_JHoh9babF9GNo_xgoS1N6QT46-K/embed?start=false&loop=true&delayms=15000" frameborder="0" width="100%" height="500" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
</div>
{% endblock %}
